# âœ‹ðŸ¤Ÿ Sign Language to Voice Conversion System

A **real-time computer vision and ML application** that converts sign language gestures into speech, improving accessibility for the speech-impaired.  
Built with **OpenCV, MediaPipe, scikit-learn, and TensorFlow**.

## Features
- **92% accuracy** in recognizing alphabets + control gestures (SPACE, DELETE, MODE).  
- Extracts advanced hand features: relative landmarks, pinch distance, finger spread.  
- **Random Forest classifier** for gesture classification.  
- Integrated **Text-to-Speech (TTS)** engine for real-time voice output.  

## Tech Stack
- **Computer Vision**: OpenCV, MediaPipe  
- **ML Models**: scikit-learn (Random Forest), TensorFlow  
- **Speech Output**: pyttsx3 / gTTS  

## Demo
[I will upload the screenshots here]

## Usage
1. Clone repo:  
   ```bash
   git clone https://github.com/yourusername/sign-language-voice.git
````

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```
3. Run system:

   ```bash
   python main.py
   ```

---

````

